{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text generation_Twitter US Airline Sentiment",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOeJwhOYV0Z5yaQkqwS2ZYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulucy19/Thinkful-Project-2019/blob/master/Text_generation_Twitter_US_Airline_Sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFZVD7MgTqpR",
        "colab_type": "text"
      },
      "source": [
        "## In the following assignments, you're required to use Twitter US Airline Sentiment data. You should access the dataset from the Thinkful database using the following credentials:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIZRKx8QSjgp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "outputId": "241353a9-2783-4832-badf-efcdd83bca3e"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import markovify\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")\n",
        "\n",
        "!python -m spacy download en"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.21.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (46.1.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.6.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.38.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K5wivZeTNy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "7646306d-ec70-4df8-af8d-62a7e3d3523b"
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'twitter_sentiment'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "tweets_df = pd.read_sql_query('select * from twitter',con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()\n",
        "\n",
        "pd.options.display.max_colwidth = None\n",
        "tweets_df.text.head(3)\n",
        "tweets_df.head(5)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>570306133677760513</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:35:52 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>570301130888122368</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>None</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:59 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>570301083672813571</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>None</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:48 -0800</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>570301031407624196</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:15:36 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>570300817074462722</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>None</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>None</td>\n",
              "      <td>2015-02-24 11:14:45 -0800</td>\n",
              "      <td>None</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index            tweet_id  ... tweet_location               user_timezone\n",
              "0      0  570306133677760513  ...           None  Eastern Time (US & Canada)\n",
              "1      1  570301130888122368  ...           None  Pacific Time (US & Canada)\n",
              "2      2  570301083672813571  ...      Lets Play  Central Time (US & Canada)\n",
              "3      3  570301031407624196  ...           None  Pacific Time (US & Canada)\n",
              "4      4  570300817074462722  ...           None  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fn7QMqebTh84",
        "colab_type": "text"
      },
      "source": [
        "### 1. First, make some data preprocessing to clean up the data if you feel necessary. You can use your solution to the assignment of the data preprocessing checkpoint of this module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK_NXYqIUInR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "#nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# below is necessary to avoid memory error of SpaCy\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "# all the processing work is done below, so it may take a while\n",
        "twitter_doc = nlp(\" \".join(tweets_df.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3wr1OYLVBoT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "eeef8a6b-47f4-4cb0-8a49-374573d8bf7a"
      },
      "source": [
        "# let's explore the objects we've built.\n",
        "print(\"The twitter_doc object is a {} object.\".format(type(twitter_doc)))\n",
        "print(\"It is {} tokens long\".format(len(twitter_doc)))\n",
        "print(\"The first three tokens are '{}'\".format(twitter_doc[:3]))\n",
        "print(\"The type of each token is {}\".format(type(twitter_doc[0])))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The twitter_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 307328 tokens long\n",
            "The first three tokens are '@VirginAmerica What @dhepburn'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcISQrs9W-xb",
        "colab_type": "text"
      },
      "source": [
        "### 2. train a Markov chain model by using only the negative sentiment tweets. Generate some random sentences. Are the generated sentences exhibit the same negative sentiment?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12s8cUz2aNra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the negative sentiment tweets.\n",
        "twitter_negative_doc = nlp(\" \".join(tweets_df[tweets_df[\"airline_sentiment\"]==\"negative\"].text))\n",
        "\n",
        "tweet_negative_sents = \" \".join([sent.text for sent in twitter_negative_doc.sents if len(sent.text) > 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpVg46rgYzsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "dd906d79-174d-4dd5-8302-1e2756dd0cda"
      },
      "source": [
        "# Generator the negative sentiment.\n",
        "neg_sentiment_generator = markovify.Text(tweet_negative_sents, state_size = 3)\n",
        "\n",
        "# Print 20 randomly-generated negative sentiments.\n",
        "for i in range(20):\n",
        "    print(neg_sentiment_generator.make_sentence(tries=100))\n",
        "    \n",
        "# Print 5 randomly-generated negative sentiments of no more than 100 characters\n",
        "for i in range(5):\n",
        "    print(neg_sentiment_generator.make_short_sentence(100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Will not be flying you again I have been rebooked for tomorrow.\n",
            "Not only was 5418 Late Flight, but we've been boarded and waiting for my bag, they don't even know why it's behind schedule.\n",
            "#delayed #again #needtocatchmynextflight #alreadyrebookedonce @United why is it so hard to SPEND money through US Air.\n",
            "“@united: @qlyss8 We don't want to chance it.\n",
            "Get a plumber @united I will be sharing this dreadful experience.\n",
            "Cancelled Flightled flight #poor customerservice @USAirways I'm glad you're sorry that I'm homeless for the night.\n",
            "I only hope and pray my bag is still in Durango and hasn't departed.\n",
            "My claim number is expired because you WON'T find my bag @united I had to sleep at the airport right now.\n",
            "I am yet to be in la tonight!\n",
            "@AmericanAir I was on hold for more than an hour.\n",
            "Now I have a girlfriend -_- @JetBlue received a voucher but if you want particulars @usairways @AmericanAir LAX connect from term 6 to term 4.\n",
            "@AmericanAir Cancelled Flightled flight with a scolding for using an overhead bin that was then Cancelled Flighted it.\n",
            "@united can't believe United can't find their airplane.\n",
            "#wedontcarebecauseyoupaidalready @USAirways I get some help too!\n",
            "I WILL think again befor Flight Booking Problems C68LD9 just times out when I can at all I'm flying @Delta.\n",
            "@united Also your at-gate monitor showed 23 empty seats on 4:15 flight which wasn't offered.\n",
            "@AmericanAir Cancelled Flightled flight pending @united is by far the worst airline.\n",
            "Just need to Cancelled Flight online instead of calling?\n",
            "@SouthwestAir I have used you guys for the 27 hour delay for a plane that was being put out of service.\n",
            "@AmericanAir my flight has been delayed and I am sympathetic.\n",
            "We will probably Cancelled Flight our flight from ST Maarten to JFK.\n",
            "I was able to do it @USAirways now the 3rd issue with the front wheels being locked.\n",
            "That is what's most frustrating @AmericanAir please DM me who I can direct details to.\n",
            "@AmericanAir now I have been holding for more than a minute.\n",
            "Your customer service for over 3 hours.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48f7Yrj0dlVG",
        "colab_type": "text"
      },
      "source": [
        "The results aer not bad, it generated the negative sentiments. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_i96tLGsXS6l",
        "colab_type": "text"
      },
      "source": [
        "### 3. Do the previous task this time bu using only the positive sentiment tweets. Generate some random sentences and observe whether they exhibit positive sentiment or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw1okjVVcBAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the positive sentiment tweets.\n",
        "twitter_positive_doc = nlp(\" \".join(tweets_df[tweets_df[\"airline_sentiment\"]==\"positive\"].text))\n",
        "\n",
        "tweet_positive_sents = \" \".join([sent.text for sent in twitter_positive_doc.sents if len(sent.text) > 1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4_45WgVdEnG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "a81cef96-02d7-49e8-9ad6-b95d7a119d85"
      },
      "source": [
        "# Generator the positive sentiments.\n",
        "positive_sentiment_generator = markovify.Text(tweet_positive_sents, state_size = 3)\n",
        "\n",
        "# Print 20 randomly-generated sentiments.\n",
        "for i in range(20):\n",
        "    print(positive_sentiment_generator.make_sentence(tries=100))\n",
        "    \n",
        "# Print 5 randomly-generated positive sentiments of no more than 100 characters\n",
        "for i in range(5):\n",
        "    print(positive_sentiment_generator.make_short_sentence(100))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@united Thanks for the reply and the follow.\n",
            "I finally made it to my destination @USAirways thanks for the follow up @JetBlue thanks for your help!\n",
            "@USAirways your team member at DCA- Tamara R. is her name was Samantha and she won over everyone on the flight @JetBlue I will!\n",
            "@SouthwestAir thanks for the info...\n",
            "This is the best part of flying!\n",
            "@USAirways your team member at DCA- Tamara R. is her name was Samantha and she won over everyone on the flight leaving from Boston to Seattle right now.\n",
            "#moneyelsewhere @united She met me from customer service at its finest @USAirways Fabulous - thank you so much that helps a ton.\n",
            "@AmericanAir Well, you guys are great can't wait to hear back from you regarding the internship opportunity!\n",
            "@VirginAmerica you have the absolute best customer service!\n",
            "She was able to change my flight 5 times for free!\n",
            "Was able to get rescheduled.\n",
            "❤️ no baggage fees.. but need to have more flight time options @SouthwestAir thank you!!! @SouthwestAir @love_dragonss oh my god thank you so much!\n",
            "#feltthelove @SouthwestAir best airline 👌 @southwestair #netneutrality Nice to see you too😊😊 @SouthwestAir @PaytonTaylor129 I love Southwest and Payton Taylor!\n",
            "👏 👍 @JetBlue I would love tix to your show!\n",
            "U guys are the best part of flying!\n",
            "#FlySWA #denverairport @SouthwestAir you guys are good @SouthwestAir loving the new planes for the JFK-LAX run.\n",
            "@AmericanAir Well, you guys are great can't wait to book my ticket now!\n",
            "@SouthwestAir Thanks for the quick responses today!! “@USAirways: @hegshmeg O” thank you for always have the most amazing customer service!\n",
            "Plz 😱❤️im dying Looking forward to flying with you guys on 2/28!\n",
            "It was amazing and made me feel valued.\n",
            "Had a great trip this past week for our honeymoon.\n",
            "@SouthwestAir thank you for the first time.\n",
            "@SouthwestAir Have had a companion pass for a few for 11 peeps on Late Flight connecting flight.\n",
            "Had to take a trip!\n",
            "Had to take a vacation!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzD9vzLWd8Lt",
        "colab_type": "text"
      },
      "source": [
        "It looks a good job for positive sentiments."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFEf8rbKXXTX",
        "colab_type": "text"
      },
      "source": [
        "### 4.This time train your Markov chain model using all the tweets and generate some random sentences. Can you say something systematic about the sentiments of the generated tweets?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6raqhjFdC5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the sentiment data\n",
        "twitter_doc = nlp(\" \".join(tweets_df.text))\n",
        "tweet_sents = \" \".join(sent.text for sent in twitter_doc if len(sent.text)>1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-bK2zdKVYOz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "0aeb238d-3bce-4204-c2d8-a13d34338b7a"
      },
      "source": [
        "# Generator sentiments.\n",
        "sentiment_generator = markovify.Text(tweet_sents, state_size = 3)\n",
        "\n",
        "# # Print 20 randomly-generated sentiments.\n",
        "for i in range(30):\n",
        "  print(sentiment_generator.make_sentence(tries=100))\n",
        "\n",
        "# Print 5 randomly-generated sentiments of no more than 100 characters\n",
        "for i in range(6):\n",
        "  print(sentiment_generator.make_short_sentence(100, tries = 100))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@USAirways do nt need to check status of my flight because crew timed out right before my 4hr flight ....\n",
            "Part of @USAirways lol thanks to you we had to entertain ourselves with witty repartee ...\n",
            "@united ... she could not access seat map so she said she would get me preferred choice seat for today ...\n",
            "@united ... she could not access seat map so she said she would get me preferred choice seat for today ...\n",
            "@AmericanAir Yes but should be able to view my reservation online ....\n",
            "Part of @USAirways lol thanks to you we had to entertain ourselves with witty repartee ...\n",
            "@USAirways do nt need to check status of my flight because crew timed out right before my 4hr flight ....\n",
            "@SouthwestAir my first flight with you today but it was Cancelled Flightled paid for first class ticket but new seat is 38E.\n",
            "Ca n't believe you would n't take full fare for first class ticket but new seat is 38E.\n",
            "It takes 13.5 hours to fly from Vegas to Omaha on SW ...\n",
            "@united how can your app show arriving aircraft is early but departing flight is delayed This type of service in not acceptable @USAirways been on hold for 95 minutes and counting ....\n",
            "Ca n't believe you would n't take full fare for first class ticket but new seat is 38E.\n",
            "Weyburn Review http://t.co/rtQyjCvTQ3 @JetBlue glitches on website re Flight Booking Problems different type of ticket ...\n",
            "nice touch lol @JetBlue think have it selected already @JetBlue last flight was Cancelled Flightled along with the subsequent one ...\n",
            "Ca n't believe you would n't take full fare for first class ticket but new seat is 38E.\n",
            "Part of @USAirways lol thanks to you we had to entertain ourselves with witty repartee ...\n",
            "@united ... she could not access seat map so she said she would get me preferred choice seat for today ...\n",
            "Ca n't believe you would n't take full fare for first class ticket but new seat is 38E.\n",
            "@united ... she could not access seat map so she said she would get me preferred choice seat for today ...\n",
            "Part of @USAirways lol thanks to you we had to entertain ourselves with witty repartee ...\n",
            "nice touch lol @JetBlue think have it selected already @JetBlue last flight was Cancelled Flightled paid for first class and gave away to Platinum Member ..\n",
            "Was charged 40 just to get the group had @SouthwestAir has the worst customer service ever Replied to complaint submitted weeks ago bout damaged bag ...\n",
            "Weyburn Review http://t.co/rtQyjCvTQ3 @JetBlue glitches on website re Flight Booking Problems different type of ticket ...\n",
            "@USAirways do nt need to check status of my flight because crew timed out right before my 4hr flight ....\n",
            "Weyburn Review http://t.co/rtQyjCvTQ3 @JetBlue glitches on website re Flight Booking Problems different type of ticket ...\n",
            "@AmericanAir Yes but should be able to view my reservation online ....\n",
            "It takes 13.5 hours to fly from Vegas to Omaha on SW ...\n",
            "Was charged 40 just to get the group had @SouthwestAir has the worst customer service ever Replied to complaint submitted weeks ago bout damaged bag ...\n",
            "@USAirways do nt need to check status of my flight because crew timed out right before my 4hr flight ....\n",
            "Weyburn Review http://t.co/rtQyjCvTQ3 @JetBlue glitches on website re Flight Booking Problems different type of ticket ...\n",
            "It takes 13.5 hours to fly from Vegas to Omaha on SW ...\n",
            "It takes 13.5 hours to fly from Vegas to Omaha on SW ...\n",
            "@AmericanAir Yes but should be able to view my reservation online ....\n",
            "Part of @USAirways lol thanks to you we had to entertain ourselves with witty repartee ...\n",
            "It takes 13.5 hours to fly from Vegas to Omaha on SW ...\n",
            "Ca n't believe you would n't take full fare for first class ticket but new seat is 38E.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_jiJrsTitqz",
        "colab_type": "text"
      },
      "source": [
        "Intersting, now you can see both negative and positive sentiments."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7sGs3zXh7zS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}