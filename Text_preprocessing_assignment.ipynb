{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text preprocessing_assignment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMI7PsaDeXwBBep+y1s6mDU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yulucy19/Thinkful-Project-2019/blob/master/Text_preprocessing_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9iDzhuNUpqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "from sqlalchemy import create_engine\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action=\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHl073f8VVVb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "051b9ddb-828a-4149-f8c5-866414d4073d"
      },
      "source": [
        "!python -m spacy download en"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BEASEMrVcE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "postgres_user = 'dsbc_student'\n",
        "postgres_pw = '7*.8G9QH21'\n",
        "postgres_host = '142.93.121.174'\n",
        "postgres_port = '5432'\n",
        "postgres_db = 'cornell_movie_dialogs'\n",
        "\n",
        "engine = create_engine('postgresql://{}:{}@{}:{}/{}'.format(\n",
        "    postgres_user, postgres_pw, postgres_host, postgres_port, postgres_db))\n",
        "\n",
        "dialogs_df = pd.read_sql_query('select * from dialogs',con=engine)\n",
        "\n",
        "# no need for an open connection, as we're only doing a single query\n",
        "engine.dispose()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3zAiIQRVj2J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "2a7809cb-6714-41a3-bbaf-fe1f1338254d"
      },
      "source": [
        "dialogs_df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>dialogs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Can we make this quick?  Roxanne Korrine and A...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Well, I thought we'd start with pronunciation,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Not the hacking and gagging and spitting part....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Okay... then how 'bout we try out some French ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>You're asking me out.  That's so cute. What's ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Forget it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>No, no, it's my fault -- we didn't have a prop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Cameron.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>The thing is, Cameron -- I'm at the mercy of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Seems like she could get a date easy enough...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                            dialogs\n",
              "0      0  Can we make this quick?  Roxanne Korrine and A...\n",
              "1      1  Well, I thought we'd start with pronunciation,...\n",
              "2      2  Not the hacking and gagging and spitting part....\n",
              "3      3  Okay... then how 'bout we try out some French ...\n",
              "4      4  You're asking me out.  That's so cute. What's ...\n",
              "5      5                                         Forget it.\n",
              "6      6  No, no, it's my fault -- we didn't have a prop...\n",
              "7      7                                           Cameron.\n",
              "8      8  The thing is, Cameron -- I'm at the mercy of a...\n",
              "9      9     Seems like she could get a date easy enough..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWJj5ZgzVwUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "714172a2-e8db-4de8-c9f3-9578937ad9f9"
      },
      "source": [
        "dialogs_df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(304446, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozEMGLBDVy9m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6453ac88-a520-485d-b358-e39dd766d46b"
      },
      "source": [
        "dialogs_df['dialogs'].head(2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Can we make this quick?  Roxanne Korrine and A...\n",
              "1    Well, I thought we'd start with pronunciation,...\n",
              "Name: dialogs, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJkZ5vA7gR3n",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VU8B-ryEV1iM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make text lowercase. remove punctuation\n",
        "dialogs_df['dialogs'] = dialogs_df['dialogs'].str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rPIro_ge9Ds",
        "colab_type": "text"
      },
      "source": [
        "### Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGwSlK4bWBX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "\n",
        "# below is necessary to avoid memory error of SpaCy\n",
        "nlp.max_length = 20000000\n",
        "\n",
        "# all the processing work is done below, so it may take a while\n",
        "dialogs_doc = nlp(\" \".join(dialogs_df.dialogs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gpl1wKPybzWn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "26dd3e32-fd96-4142-cf2d-24a86cbd4a2e"
      },
      "source": [
        "# let's explore the objects we've built.\n",
        "print(\"The dialogs_doc object is a {} object.\".format(type(dialogs_doc)))\n",
        "print(\"It is {} tokens long\".format(len(dialogs_doc)))\n",
        "print(\"The first three tokens are '{}'\".format(dialogs_doc[:3]))\n",
        "print(\"The type of each token is {}\".format(type(dialogs_doc[0])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dialogs_doc object is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 4279540 tokens long\n",
            "The first three tokens are 'can we make'\n",
            "The type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZ7JpyEogX8U",
        "colab_type": "text"
      },
      "source": [
        "### Removing Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DQiABWcfzNe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dialogs_without_stopwords = [token for token in dialogs_doc if not token.is_stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mpFsP4Bgpt3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e2f69d36-c351-4468-e0ca-7b5b3ca89e47"
      },
      "source": [
        "# utility function to calculate how frequently words appear in the text\n",
        "def word_frequencies(text):\n",
        "    \n",
        "    # build a list of words\n",
        "    # strip out punctuation\n",
        "    words = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            words.append(token.text)\n",
        "            \n",
        "    # build and return a Counter object containing word counts\n",
        "    return Counter(words)\n",
        "\n",
        "# instantiate our list of most common words.\n",
        "dialogs_word_freq = word_frequencies(dialogs_without_stopwords).most_common(10)\n",
        "print('\\ndialogs:', dialogs_word_freq)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dialogs: [(' ', 83751), ('know', 21613), ('like', 15026), ('got', 13284), ('want', 11042), ('think', 10761), ('right', 10031), ('going', 8869), ('oh', 7918), ('good', 7465)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg0Y60A5hIKw",
        "colab_type": "text"
      },
      "source": [
        "### Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lE5p0B0hAGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "52d67ccc-f1e2-4b3a-ee0c-1ee824902e82"
      },
      "source": [
        "# utility function to calculate how frequently lemas appear in the text\n",
        "def lemma_frequencies(text):\n",
        "    \n",
        "    # build a list of lemas\n",
        "    # strip out punctuation\n",
        "    lemmas = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            lemmas.append(token.lemma_)\n",
        "            \n",
        "    # build and return a Counter object containing lemma counts\n",
        "    return Counter(lemmas)\n",
        "\n",
        "# instantiate our list of most common words.\n",
        "dialogs_lemma_freq = lemma_frequencies(dialogs_without_stopwords).most_common(10)\n",
        "print('\\ndialogs:', dialogs_lemma_freq)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dialogs: [(' ', 83751), ('know', 24766), ('go', 16895), ('get', 15820), ('like', 15620), ('think', 15068), ('want', 13983), ('come', 10616), ('tell', 10493), ('right', 10131)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6WY_ZdThZcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}